# system/metrics/MetricAggregator.py
import math
from typing import Dict, List, Any

# Configuration constraints based on Axiom I (UMA) 
# and implied structure (0.0 to 1.0 scoring).

class MetricAggregator:
    """
    Manages the collection, standardization, weighted aggregation, and final 
    calculation of the Total Evolved Mandate Metric (TEMM) score.
    TEMM is the primary quantitative measure of utility maximization (Axiom I).
    """

    # NOTE: In production, this schema should be dynamically loaded via a Configuration Manager
    # (See architectural proposal)
    DEFAULT_SCHEMA = {
        "EfficiencyScore": {"range": (0.0, 100.0), "weight": 0.45}, 
        "ResourceUtilization": {"range": (0.0, 1.0), "weight": 0.30}, 
        "MandateFulfillmentRatio": {"range": (0.5, 1.0), "weight": 0.25}
    }

    def __init__(self, logger: Any, schema: Dict[str, Dict[str, Any]] = None):
        self.raw_metrics: Dict[str, List[Dict[str, float]]] = {}
        self.logger = logger
        
        # Load schema and validate weights
        self.schema = self._validate_and_merge_schema(schema or self.DEFAULT_SCHEMA)
        
        total_weight = sum(item["weight"] for item in self.schema.values())
        if not math.isclose(total_weight, 1.0, abs_tol=1e-6):
             self.logger.log_error(f"TEMM Schema weights must sum to 1.0. Current sum: {total_weight}")
             self._normalize_weights(total_weight)


    def _normalize_weights(self, total_weight: float):
        """Ensures weights strictly sum to 1.0 if an error is detected."""
        if total_weight > 0:
            for metric in self.schema:
                self.schema[metric]["weight"] /= total_weight
            self.logger.log_warning(f"TEMM weights renormalized to 1.0.")

    def _validate_and_merge_schema(self, new_schema: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """Ensures schema integrity and merges defaults."""
        final_schema = {}
        # Start with defaults and allow overriding
        for metric, definition in self.DEFAULT_SCHEMA.items():
            final_schema[metric] = definition.copy() 
            
            if metric in new_schema:
                if 'range' in new_schema[metric] and len(new_schema[metric]['range']) == 2:
                    final_schema[metric]['range'] = new_schema[metric]['range']
                if 'weight' in new_schema[metric]:
                    final_schema[metric]['weight'] = new_schema[metric]['weight']
        
        return final_schema

    def ingest_runtime_data(self, stage: str, data: Dict[str, float]):
        """
        Ingests data points generated by SGS during execution stages (S05-S07).
        Only stores data relevant to the TEMM calculation defined in the schema.
        """
        if stage not in self.raw_metrics:
            self.raw_metrics[stage] = []
        
        filtered_data = {k: v for k, v in data.items() if k in self.schema}
        
        if filtered_data:
            self.raw_metrics[stage].append(filtered_data)
            self.logger.log_debug(f"Metrics ingested for {stage} ({len(filtered_data)} relevant points)."_standardize_metric)
        else:
            self.logger.log_debug(f"Ingestion for {stage} ignored. No relevant TEMM metrics found.")


    def _standardize_metric(self, metric_name: str, value: float) -> float:
        """
        Standardizes a raw metric value (Min-Max normalization) to the [0.0, 1.0] range.
        Scores outside the defined range are capped at 0.0 or 1.0.
        """
        if metric_name not in self.schema:
            return 0.0

        min_val, max_val = self.schema[metric_name]["range"]
        
        if max_val <= min_val:
            # Handle edge case where bounds are invalid
            return 1.0 if value >= max_val else 0.0

        # Min-Max Normalization: (x - min) / (max - min)
        standardized = (value - min_val) / (max_val - min_val)
        
        # Cap the score to ensure it remains within the defined bounds [0.0, 1.0]
        return max(0.0, min(1.0, standardized))


    def calculate_temm(self) -> float:
        """
        Aggregates and standardizes raw metrics against the schema, applying 
        defined weights to produce the final TEMM score (0.0 - 1.0).
        """
        if not any(self.raw_metrics.values()):
            self.logger.log_warning("No raw metrics available. TEMM set to 0.0.")
            return 0.0

        standardized_scores_by_metric = {m: [] for m in self.schema}

        # 1. Aggregate and Standardize all points
        for stage_data in self.raw_metrics.values():
            for data_point in stage_data:
                for metric_name, value in data_point.items():
                    if metric_name in self.schema:
                        standardized_score = self._standardize_metric(metric_name, value)
                        standardized_scores_by_metric[metric_name].append(standardized_score)

        # 2. Calculate average score per metric and apply weights
        temm_score = 0.0
        
        for metric_name, definition in self.schema.items():
            scores = standardized_scores_by_metric[metric_name]
            weight = definition["weight"]
            
            if scores:
                avg_score = sum(scores) / len(scores)
                weighted_score = avg_score * weight
                temm_score += weighted_score
            else:
                self.logger.log_debug(f"Metric '{metric_name}' missing data points. Weight {weight} unapplied.")

        final_temm = min(1.0, temm_score)
        
        self.logger.log_info(f"TEMM Calculated: {final_temm:.6f}")
        return final_temm

    def get_report(self) -> dict:
        """
        Returns the final calculated TEMM score and supporting raw data for GAX auditing.
        """
        return {
            "TEMM": self.calculate_temm(),
            "RawDataSnapshot": self.raw_metrics,
            "StandardizationSchema": self.schema,
        }