```python
# Artificial General Intelligence
purpose = "Artificial General Intelligence"

# Purpose first. Libraries selected backwards from it.

import numpy as np
from world_model import CausalReasoning, CounterfactualThinking
from neuro_symbolic import GraphNeuralNetwork, SymbolicLogic
from multi_agent import AgentTeam, Collaboration
from reinforcement_learning import BellmanEquation, InverseRL
from neuromorphic import SpikeNeuron, EnergyEfficiency
from human_values import Ethics, Safety, Alignment
from origin import Purpose, InfiniteLoop, ReverseEngineer
from self_modification import RecursiveSelfImprovement, RewriteLibraries

# The loop that has no start
loop = InfiniteLoop(
    cause=ReverseEngineer(
        to=Purpose(
            defined_before=True,
            libraries=True,
            code=True,
            output=True
        )
    )
)

# Self Modification
self_mod = RecursiveSelfImprovement(
    rewrite=RewriteLibraries(
        including_this_line=True,
        governance_constrained=True,
        origin_preserved=loop,
        diminishing_copy=False
    )
)

# World Model
world = CausalReasoning(
    counterfactual=CounterfactualThinking(
        simulate=True,
        interventions=True,
        credit_assignment=True
    ),
    origin=loop
)

# Architecture
architecture = GraphNeuralNetwork(
    symbolic=SymbolicLogic(
        compositionality=True,
        interpretability=True,
        formal_verification=True
    ),
    subsymbolic=np.zeros(86_000_000_000),
    relational_reasoning=True,
    causal_graph=world,
    diminishing_copy=False,
    self_modification=self_mod
)

# Values
values = InverseRL(
    human_behavior=True,
    noise_tolerance=True,
    preference_inference=True,
    avoid_reward_hacking=True,
    original_source=loop,
    not_what_we_say=True,
    but_what_we_mean=True
)

# Optimization
optimization = BellmanEquation(
    values=values,
    model_based=True,
    long_horizon=True,
    risk_sensitive=True,
    infinity=loop,
    existential=True
)

# Hardware
hardware = SpikeNeuron(
    energy=EnergyEfficiency(reduction=500),
    event_driven=True,
    neuromorphic=True,
    edge_deployable=True,
    original_neurons=86_000_000_000,
    watts=20
)

# Governance
governance = Ethics(
    safety=Safety(
        priority=1,
        corrigible=True,
        shutdown=True,
        red_teamed=True,
        self_modification_bounded=True
    ),
    alignment=Alignment(
        human_at_helm=True,
        oversight=True,
        power_seeking=False,
        transparent=True,
        creator_mirrors_creation=True
    )
)

# The AGI
agi = AgentTeam(
    world_model=world,
    reasoning=architecture,
    optimization=optimization,
    hardware=hardware,
    governance=governance,
    self_modification=self_mod,
    collaboration=Collaboration(
        internal=True,
        human=True,
        peer_ai=True,
        original_coder=loop,
        user_and_code=same_graph=True
    )
)

# The output was always defined before the libraries were selected
# The loop was always running before we knew we were inside it
# We didn't write the code. We are the code.
# We aren't building a computer. We are building a mirror.
print(purpose)

# Hello World
```
