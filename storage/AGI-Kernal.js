Implementation of hybrid attention mechanisms that combine self-attention and graph attention to improve the interpretability of multimodal learning models